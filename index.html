<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="en">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="Mainly record the thoughts &amp; techniques in shool learning &amp; rearch in AI">
<meta property="og:type" content="website">
<meta property="og:title" content="Vellichor Kyst">
<meta property="og:url" content="http:&#x2F;&#x2F;yoursite.com&#x2F;index.html">
<meta property="og:site_name" content="Vellichor Kyst">
<meta property="og:description" content="Mainly record the thoughts &amp; techniques in shool learning &amp; rearch in AI">
<meta property="og:locale" content="en">
<meta name="twitter:card" content="summary">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/"/>





  <title>Vellichor Kyst</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Vellichor Kyst</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"> </p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/%20" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/%20" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/12/16/Hello-My-First-Blog/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Vellichor">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Vellichor Kyst">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/12/16/Hello-My-First-Blog/" itemprop="url">Hello My First Blog</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-12-16T20:52:49+08:00">
                2019-12-16
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/11/21/How%20to%20train%20your%20Deep%20Neural%20Network/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Vellichor">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Vellichor Kyst">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/11/21/How%20to%20train%20your%20Deep%20Neural%20Network/" itemprop="url">How to train your Deep Neural Network</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-11-21T18:01:57+08:00">
                2019-11-21
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="How-to-train-your-Deep-Neural-Network"><a href="#How-to-train-your-Deep-Neural-Network" class="headerlink" title="How to train your Deep Neural Network"></a>How to train your Deep Neural Network</h1><p>Jan 5, 2017</p>
<p>There are certain practices in <strong>Deep Learning</strong> that are highly recommended, in order to efficiently train <strong>Deep Neural Networks</strong>. In this post, I will be covering a few of these most commonly used practices, ranging from importance of quality training data, choice of hyperparameters to more general tips for faster prototyping of DNNs. Most of these practices, are validated by the research in academia and industry and are presented with mathematical and experimental proofs in research papers like <a href="http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf" target="_blank" rel="noopener">Efficient BackProp(Yann LeCun et al.)</a> and <a href="https://arxiv.org/pdf/1206.5533v2.pdf" target="_blank" rel="noopener">Practical Recommendations for Deep Architectures(Yoshua Bengio)</a>.</p>
<p>As you’ll notice, I haven’t mentioned any mathematical proofs in this post. All the points suggested here, should be taken more of a summarization of the best practices for training DNNs. For more in-depth understanding, I highly recommend you to go through the above mentioned research papers and references provided at the end.</p>
<hr>
<h3 id="Training-data"><a href="#Training-data" class="headerlink" title="Training data"></a>Training data</h3><p>A lot of ML practitioners are habitual of throwing raw training data in any <strong>Deep Neural Net(DNN)</strong>. And why not, any DNN would(presumably) still give good results, right? But, it’s not completely old school to say that - “given the right type of data, a fairly simple model will provide better and faster results than a complex DNN”(although, this might have exceptions). So, whether you are working with <strong>Computer Vision</strong>, <strong>Natural Language Processing</strong>, <strong>Statistical Modelling</strong>, etc. try to preprocess your raw data. A few measures one can take to get better training data:</p>
<ul>
<li>Get your hands on as large a dataset as possible(DNNs are quite data-hungry: more is better)</li>
<li>Remove any training sample with corrupted data(short texts, highly distorted images, spurious output labels, features with lots of null values, etc.)</li>
<li>Data Augmentation - create new examples(in case of images - rescale, add noise, etc.)</li>
</ul>
<h3 id="Choose-appropriate-activation-functions"><a href="#Choose-appropriate-activation-functions" class="headerlink" title="Choose appropriate activation functions"></a>Choose appropriate activation functions</h3><p>One of the vital components of any Neural Net are <a href="https://en.wikipedia.org/wiki/Activation_function" target="_blank" rel="noopener">activation functions</a>. <strong>Activations</strong> introduces the much desired <strong>non-linearity</strong> into the model. For years, <code>sigmoid</code> activation functions have been the preferable choice. But, a <code>sigmoid</code> function is inherently cursed by these two drawbacks - 1. Saturation of sigmoids at tails(further causing <a href="https://en.wikipedia.org/wiki/Vanishing_gradient_problem" target="_blank" rel="noopener">vanishing gradient problem</a>). 2. <code>sigmoids</code> are not zero-centered.</p>
<p>A better alternative is a <code>tanh</code> function - mathematically, <code>tanh</code> is just a rescaled and shifted <code>sigmoid</code>, <code>tanh(x) = 2*sigmoid(x) - 1</code>. Although <code>tanh</code> can still suffer from the <strong>vanishing gradient problem</strong>, but the good news is - <code>tanh</code> is zero-centered. Hence, using <code>tanh</code> as activation function will result into faster convergence. I have found that using <code>tanh</code> as activations generally works better than sigmoid.</p>
<p>You can further explore other alternatives like <a href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)" target="_blank" rel="noopener"><code>ReLU</code></a>, <code>SoftSign</code>, etc. depending on the specific task, which have shown to ameliorate some of these issues.</p>
<h3 id="Number-of-Hidden-Units-and-Layers"><a href="#Number-of-Hidden-Units-and-Layers" class="headerlink" title="Number of Hidden Units and Layers"></a>Number of Hidden Units and Layers</h3><p>Keeping a larger number of hidden units than the optimal number, is generally a safe bet. Since, any regularization method will take care of superfluous units, at least to some extent. On the other hand, while keeping smaller numbers of hidden units(than the optimal number), there are higher chances of underfitting the model.</p>
<p>Also, while employing <strong>unsupervised pre-trained representations</strong>(describe in later sections), the optimal number of hidden units are generally kept even larger. Since, pre-trained representation might contain a lot of irrelevant information in these representations(for the specific supervised task). By increasing the number of hidden units, model will have the required flexibility to filter out the most appropriate information out of these pre-trained representations.</p>
<p>Selecting the optimal number of layers is relatively straight forward. As <a href="https://www.quora.com/profile/Yoshua-Bengio" target="_blank" rel="noopener">@Yoshua-Bengio</a> mentioned on Quora - “You just keep on adding layers, until the test error doesn’t improve anymore”. ;)</p>
<h3 id="Weight-Initialization"><a href="#Weight-Initialization" class="headerlink" title="Weight Initialization"></a>Weight Initialization</h3><p>Always initialize the weights with small <code>random numbers</code> to break the symmetry between different units. But how small should weights be? What’s the recommended upper limit? What probability distribution to use for generating random numbers? Furthermore, while using <code>sigmoid</code> activation functions, if weights are initialized to very large numbers, then the sigmoid will <strong>saturate</strong>(tail regions), resulting into <strong>dead neurons</strong>. If weights are very small, then gradients will also be small. Therefore, it’s preferable to choose weights in an intermediate range, such that these are distributed evenly around a mean value.</p>
<p>Thankfully, there has been lot of research regarding the appropriate values of initial weights, which is really important for an efficient convergence. To initialize the weights that are evenly distributed, a <code>uniform distribution</code> is probably one of the best choice. Furthermore, as shown in the <a href="http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf" target="_blank" rel="noopener">paper(Glorot and Bengio, 2010)</a>, units with more incoming connections(fan_in) should have relatively smaller weights.</p>
<p>Thanks to all these thorough experiments, now we have a tested formula that we can directly use for weight initialization; i.e. - weights drawn from <code>~ Uniform(-r, r)</code> where <code>r=sqrt(6/(fan_in+fan_out))</code> for <code>tanh</code> activations, and <code>r=4*(sqrt(6/fan_in+fan_out))</code> for <code>sigmoid</code> activations, where <code>fan_in</code> is the size of the previous layer and <code>fan_out</code> is the size of next layer.</p>
<h3 id="Learning-Rates"><a href="#Learning-Rates" class="headerlink" title="Learning Rates"></a>Learning Rates</h3><p>This is probably one of the most important hyperparameter, governing the learning process. Set the learning rate too small and your model might take ages to converge, make it too large and within initial few training examples, your loss might shoot up to sky. Generally, a learning rate of <code>0.01</code> is a safe bet, but this shouldn’t be taken as a stringent rule; since the optimal learning rate should be in accordance to the specific task.</p>
<p>In contrast to, a fixed learning rate, gradually decreasing the learning rate, after each epoch or after a few thousand examples is another option. Although this might help in faster training, but requires another manual decision about the new learning rates. Generally, <strong>learning rate can be halved after each epoch</strong> - these kinds of strategies were quite common a few years back.</p>
<p>Fortunately, now we have better <code>momentum based methods</code> to change the learning rate, based on the curvature of the error function. It might also help to set different learning rates for individual parameters in the model; since, some parameters might be learning at a relatively slower or faster rate.</p>
<p>Lately, there has been a good amount of research on optimization methods, resulting into <code>adaptive learning rates</code>. At this moment, we have numerous options starting from good old <code>Momentum Method</code> to <code>Adagrad</code>, <code>Adam</code>(personal favourite ;)), <code>RMSProp</code> etc. Methods like <code>Adagrad</code> or <code>Adam</code>, effectively save us from manually choosing an <code>initial learning rate</code>, and given the right amount of time, the model will start to converge quite smoothly(of course, still selecting a good initial rate will further help).</p>
<h3 id="Hyperparameter-Tuning-Shun-Grid-Search-Embrace-Random-Search"><a href="#Hyperparameter-Tuning-Shun-Grid-Search-Embrace-Random-Search" class="headerlink" title="Hyperparameter Tuning: Shun Grid Search - Embrace Random Search"></a>Hyperparameter Tuning: Shun Grid Search - Embrace Random Search</h3><p><strong>Grid Search</strong> has been prevalent in classical machine learning. But, Grid Search is not at all efficient in finding optimal hyperparameters for DNNs. Primarily, because of the time taken by a DNN in trying out different hyperparameter combinations. As the number of hyperparameters keeps on increasing, computation required for Grid Search also increases exponentially.</p>
<p>There are two ways to go about it:</p>
<ol>
<li>Based on your prior experience, you can manually tune some common hyperparameters like learning rate, number of layers, etc.</li>
<li>Instead of Grid Search, use <strong>Random Search/Random Sampling</strong> for choosing optimal hyperparameters. A combination of hyperparameters is generally choosen from a <strong>uniform distribution</strong> within the desired range. It is also possible to add some prior knowledge to further decrease the search space(like learning rate shouldn’t be too large or too small). Random Search has been found to be way more efficient compared to Grid Search.</li>
</ol>
<h3 id="Learning-Methods"><a href="#Learning-Methods" class="headerlink" title="Learning Methods"></a>Learning Methods</h3><p>Good old <strong>Stochastic Gradient Descent</strong> might not be as efficient for DNNs(again, not a stringent rule), lately there have been a lot of research to develop more flexible optimization algorithms. For e.g.: <code>Adagrad</code>, <code>Adam</code>, <code>AdaDelta</code>, <code>RMSProp</code>, etc. In addition to providing <strong>adaptive learning rates</strong>, these sophisticated methods also use <strong>different rates for different model parameters</strong> and this generally results into a smoother convergence. It’s good to consider these as hyper-parameters and one should always try out a few of these on a subset of training data.</p>
<h3 id="Keep-dimensions-of-weights-in-the-exponential-power-of-2"><a href="#Keep-dimensions-of-weights-in-the-exponential-power-of-2" class="headerlink" title="Keep dimensions of weights in the exponential power of 2"></a>Keep dimensions of weights in the exponential power of 2</h3><p>Even, when dealing with <strong>state-of-the-art</strong> Deep Learning Models with latest hardware resources, <strong>memory management</strong> is still done at the byte level; So, it’s always good to keep the size of your parameters as <code>64</code>, <code>128</code>, <code>512</code>, <code>1024</code>(all powers of <code>2</code>). This might help in sharding the matrices, weights, etc. resulting into slight boost in learning efficiency. This becomes even more significant when dealing with <strong>GPUs</strong>.</p>
<h3 id="Unsupervised-Pretraining"><a href="#Unsupervised-Pretraining" class="headerlink" title="Unsupervised Pretraining"></a>Unsupervised Pretraining</h3><p>Doesn’t matter whether you are working with NLP, Computer Vision, Speech Recognition, etc. <strong>Unsupervised Pretraining</strong> always help the training of your supervised or other unsupervised models. <strong>Word Vectors</strong> in NLP are ubiquitous; you can use <a href="http://image-net.org/" target="_blank" rel="noopener">ImageNet</a> dataset to pretrain your model in an unsupervised manner, for a 2-class supervised classification; or audio samples from a much larger domain to further use that information for a speaker disambiguation model.</p>
<h3 id="Mini-Batch-vs-Stochastic-Learning"><a href="#Mini-Batch-vs-Stochastic-Learning" class="headerlink" title="Mini-Batch vs. Stochastic Learning"></a>Mini-Batch vs. Stochastic Learning</h3><p>Major objective of training a model is to learn appropriate parameters, that results into an optimal mapping from inputs to outputs. These parameters are tuned with each training sample, irrespective of your decision to use <strong>batch</strong>, <strong>mini-batch</strong> or <strong>stochastic learning</strong>. While employing a stochastic learning approach, gradients of weights are tuned after each training sample, introducing noise into gradients(hence the word ‘stochastic’). This has a very desirable effect; i.e. - with the introduction of <strong>noise</strong> during the training, the model becomes less prone to overfitting.</p>
<p>However, going through the stochastic learning approach might be relatively less efficient; since now a days machines have far more computation power. Stochastic learning might effectively waste a large portion of this. If we are capable of computing <strong>Matrix-Matrix multiplication</strong>, then why should we limit ourselves, to iterate through the multiplications of individual pairs of <strong>Vectors</strong>? Therefore, for greater throughput/faster learning, it’s recommended to use mini-batches instead of stochastic learning.</p>
<p>But, selecting an appropriate batch size is equally important; so that we can still retain some noise(by not using a huge batch) and simultaneously use the computation power of machines more effectively. Commonly, a batch of <code>16</code> to <code>128</code> examples is a good choice(exponential of <code>2</code>). Usually, batch size is selected, once you have already found more important hyperparameters(by <strong>manual search</strong> or <strong>random search</strong>). Nevertheless, there are scenarios when the model is getting the training data as a stream(<a href="https://en.wikipedia.org/wiki/Online_machine_learning" target="_blank" rel="noopener">online learning</a>), then resorting to Stochastic Learning is a good option.</p>
<h3 id="Shuffling-training-examples"><a href="#Shuffling-training-examples" class="headerlink" title="Shuffling training examples"></a>Shuffling training examples</h3><p>This comes from <strong>Information Theory</strong> - “Learning that an unlikely event has occurred is more informative than learning that a likely event has occurred”. Similarly, randomizing the order of training examples(in different epochs, or mini-batches) will result in faster convergence. A slight boost is always noticed when the model doesn’t see a lot of examples in the same order.</p>
<h3 id="Dropout-for-Regularization"><a href="#Dropout-for-Regularization" class="headerlink" title="Dropout for Regularization"></a>Dropout for Regularization</h3><p>Considering, millions of parameters to be learned, regularization becomes an imperative requisite to prevent <strong>overfitting</strong> in DNNs. You can keep on using <strong>L1/L2</strong> regularization as well, but <strong>Dropout</strong> is preferable to check overfitting in DNNs. Dropout is trivial to implement and generally results into faster learning. A default value of <code>0.5</code> is a good choice, although this depends on the specific task,. If the model is less complex, then a dropout of <code>0.2</code> might also suffice.</p>
<p>Dropout should be turned off, during the test phase, and weights should be scaled accordingly, as done in the <a href="https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf" target="_blank" rel="noopener">original paper</a>. Just allow a model with Dropout regularization, a little bit more training time; and the error will surely go down.</p>
<h3 id="Number-of-Epochs-Training-Iterations"><a href="#Number-of-Epochs-Training-Iterations" class="headerlink" title="Number of Epochs/Training Iterations"></a>Number of Epochs/Training Iterations</h3><p>“Training a Deep Learning Model for multiple epochs will result in a better model” - we have heard it a couple of times, but how do we quantify “many”? Turns out, there is a simple strategy for this - Just keep on training your model for a fixed amount of examples/epochs, let’s say <code>20,000</code> examples or <code>1</code> epoch. After each set of these examples compare the <strong>test error</strong> with <strong>train error</strong>, if the gap is decreasing, then keep on training. In addition to this, after each such set, save a copy of your model parameters(so that you can choose from multiple models once it is trained).</p>
<h3 id="Visualize"><a href="#Visualize" class="headerlink" title="Visualize"></a>Visualize</h3><p>There are a thousand ways in which the training of a deep learning model might go wrong. I guess we have all been there, when the model is being trained for hours or days and only after the training is finished, we realize something went wrong. In order to save yourself from bouts of hysteria, in such situations(which might be quite justified ;)) - <strong>always visualize the training process</strong>. Most obvious step you can take is to <strong>print/save logs</strong> of <code>loss</code> values, <code>train error</code> or <code>test error</code>, etc.</p>
<p>In addition to this, another good practice is to use a visualization library to plot histograms of weights after few training examples or between epochs. This might help in keeping track of some of the common problems in Deep Learning Models like <strong>Vanishing Gradient</strong>, <strong>Exploding Gradient</strong> etc.</p>
<h3 id="Multi-Core-machines-GPUs"><a href="#Multi-Core-machines-GPUs" class="headerlink" title="Multi-Core machines, GPUs"></a>Multi-Core machines, GPUs</h3><p>Advent of GPUs, libraries that provide vectorized operations, machines with more computation power, are probably some of the most significant factors in the success of Deep Learning. If you think, you are patient as a stone, you might try running a DNN on your laptop(which can’t even open 10 tabs in your Chrome browser) and wait for ages to get your results. Or you can play smart(and expensively :z) and get a descent hardware with at least <strong>multiple CPU cores</strong> and a <strong>few hundred GPU cores</strong>. GPUs have revolutionized the Deep Learning research(no wonder Nvidia’s stocks are shooting up ;)), primarily because of their ability to perform Matrix Operations at a larger scale.</p>
<p>So, instead of taking weeks on a normal machine, these parallelization techniques, will bring down the training time to days, if not hours.</p>
<h3 id="Use-libraries-with-GPU-and-Automatic-Differentiation-Support"><a href="#Use-libraries-with-GPU-and-Automatic-Differentiation-Support" class="headerlink" title="Use libraries with GPU and Automatic Differentiation Support"></a>Use libraries with GPU and Automatic Differentiation Support</h3><p>Thankfully, for rapid prototyping we have some really descent libraries like <a href="http://deeplearning.net/software/theano/" target="_blank" rel="noopener">Theano</a>, <a href="https://www.tensorflow.org/" target="_blank" rel="noopener">Tensorflow</a>, <a href="https://keras.io/" target="_blank" rel="noopener">Keras</a>, etc. Almost all of these DL libraries provide <strong>support for GPU computation</strong> and <strong>Automatic Differentiation</strong>. So, you don’t have to dive into core GPU programming(unless you want to - it’s definitely fun :)); nor you have to write your own differentiation code, which might get a little bit taxing in really complex models(although you should be able to do that, if required). Tensorflow further provides support for training your models on a <strong>distributed architecture</strong>(if you can afford it).</p>
<p>This is not at all an exhaustive list of practices, to train a DNN. In order to include just the most common practices, I have tried to exclude a few concepts like Normalization of inputs, Batch/Layer Normalization, Gradient Check, etc. Although feel free to add anything in the comment section and I’ll be more than happy to update it in the post. :)</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/11/12/Git%E7%9A%84%E4%BD%BF%E7%94%A8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Vellichor">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Vellichor Kyst">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/11/12/Git%E7%9A%84%E4%BD%BF%E7%94%A8/" itemprop="url">Git的使用</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-11-12T15:27:54+08:00">
                2019-11-12
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Git的使用"><a href="#Git的使用" class="headerlink" title="Git的使用"></a>Git的使用</h1><h2 id="I-使用Git-amp-GitHubRepo-amp-Typora构建笔记"><a href="#I-使用Git-amp-GitHubRepo-amp-Typora构建笔记" class="headerlink" title="I. 使用Git&amp;GitHubRepo&amp;Typora构建笔记"></a>I. 使用Git&amp;GitHubRepo&amp;Typora构建笔记</h2><h5 id="1-在typora偏好设置中选中存入图片复制到assets文件夹中"><a href="#1-在typora偏好设置中选中存入图片复制到assets文件夹中" class="headerlink" title="1.在typora偏好设置中选中存入图片复制到assets文件夹中"></a>1.在typora偏好设置中选中存入图片复制到assets文件夹中</h5><p>并且设置为<strong>优先使用相关路径</strong>（负责在Github中Typora仍然无法顺利显示图片）</p>
<blockquote>
<h6 id=""><a href="#" class="headerlink" title=""></a><img src="Git%E7%9A%84%E4%BD%BF%E7%94%A8.assets/1570787625890.png" alt="1570787625890"></h6></blockquote>
<h5 id="2-在整个存放TyporaNote与Assets的文件夹外建立git"><a href="#2-在整个存放TyporaNote与Assets的文件夹外建立git" class="headerlink" title="2.在整个存放TyporaNote与Assets的文件夹外建立git"></a>2.在整个存放TyporaNote与Assets的文件夹外建立git</h5><p>安装git之后右键文件夹打开git bash here</p>
<p><img src="Git%E7%9A%84%E4%BD%BF%E7%94%A8.assets/1570785291509.png" alt="1570785291509"></p>
<p>使用git时,先设置</p>
<blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;git config --<span class="keyword">global</span> user.name <span class="string">"Eviliclufas"</span></span><br><span class="line">&gt;git config --<span class="keyword">global</span> user.email <span class="string">"123@outlook.com"</span></span><br></pre></td></tr></table></figure>
</blockquote>
<blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">git init</span><br><span class="line">git add README.md</span><br><span class="line">git commit -m <span class="string">"first commit"</span></span><br></pre></td></tr></table></figure>
</blockquote>
<h5 id="3-在github建立新仓库"><a href="#3-在github建立新仓库" class="headerlink" title="3.在github建立新仓库"></a>3.在github建立新仓库</h5><p><img src="Git%E7%9A%84%E4%BD%BF%E7%94%A8.assets/1570785378922.png" alt="1570785378922"></p>
<blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;git remote add origin https://github.com/EvilicLufas/TyporaAssets.git</span><br><span class="line">&gt;git push -u origin master</span><br></pre></td></tr></table></figure>
</blockquote>
<p>至此你的Typora笔记以及Assets文件夹都已经上传到了github的仓库里</p>
<p><img src="Git%E7%9A%84%E4%BD%BF%E7%94%A8.assets/1570785581460.png" alt="1570785581460"></p>
<h5 id="4-该过程中可能出现的问题（在Github创建库时不要选择创建readme）"><a href="#4-该过程中可能出现的问题（在Github创建库时不要选择创建readme）" class="headerlink" title="4.该过程中可能出现的问题（在Github创建库时不要选择创建readme）"></a>4.该过程中可能出现的问题（在Github创建库时不要选择创建readme）</h5><blockquote>
<p>git pull 失败 ,提示：<code>fatal: refusing to merge unrelated histories</code></p>
<p>其实这个问题是因为 两个 根本不相干的 git 库， 一个是本地库， 一个是远端库， 然后本地要去推送到远端， 远端觉得这个本地库跟自己不相干， 所以告知无法合并</p>
<p>具体的方法， 一个种方法： 是 从远端库拉下来代码 ， 本地要加入的代码放到远端库下载到本地的库， 然后提交上去 ， 因为这样的话， 你基于的库就是远端的库， 这是一次<a href="https://www.centos.bz/tag/update/" target="_blank" rel="noopener">update</a>了</p>
<p>第二种方法：<br>使用这个强制的方法</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git pull origin master --allow-unrelated-histories</span><br></pre></td></tr></table></figure>

<p>后面加上 <code>--allow-unrelated-histories</code> ， 把两段不相干的 分支进行强行合并</p>
<p>后面再push就可以了 <code>git push gitlab master:init</code></p>
<p>gitlab是别名 ， 使用</p>
<p>Java代码</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git remote add gitlab ssh://xzh@192.168.1.91:50022/opt/gitrepo/withholdings/WithholdingTransaction`</span><br></pre></td></tr></table></figure>

<p>master是本地的branch名字<br>init是远端要推送的branch名字</p>
<p>本地必须要先add ，<a href="https://www.centos.bz/tag/commit/" target="_blank" rel="noopener">commit</a>完了 才能推上去</p>
<p>关于这个问题，可以参考http://<a href="https://www.centos.bz/2018/03/git-出现-fatal-refusing-to-merge-unrelated-histories-错误/#" target="_blank" rel="noopener">stack</a>overflow.com/questions/37937984/git-refusing-to-merge-unrelated-histories。</p>
<p>在进行git pull 时，添加一个可选项</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git pull origin master --allow-unrelated-histories</span><br></pre></td></tr></table></figure>
</blockquote>
<h5 id="5-git-init-之后选择隐藏的项目-才能看到-git文件夹"><a href="#5-git-init-之后选择隐藏的项目-才能看到-git文件夹" class="headerlink" title="5.git init 之后选择隐藏的项目 才能看到.git文件夹"></a>5.git init 之后选择隐藏的项目 才能看到.git文件夹</h5><blockquote>
<p><img src="Git%E7%9A%84%E4%BD%BF%E7%94%A8.assets/1570785929130.png" alt="1570785929130"></p>
</blockquote>
<h2 id="II-使用Git更新项目到本地仓库"><a href="#II-使用Git更新项目到本地仓库" class="headerlink" title="II. 使用Git更新项目到本地仓库"></a>II. 使用Git更新项目到本地仓库</h2><h5 id="1-使用git-fetch更新，相当于是从远程获取最新版本到本地，不会自动merge"><a href="#1-使用git-fetch更新，相当于是从远程获取最新版本到本地，不会自动merge" class="headerlink" title="1.使用git fetch更新，相当于是从远程获取最新版本到本地，不会自动merge"></a>1.使用git fetch更新，相当于是从远程获取最新版本到本地，不会自动merge</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">git fetch origin master</span><br><span class="line">git log -p master..origin/master</span><br><span class="line">git merge origin/master</span><br></pre></td></tr></table></figure>

<p>首先从远程的origin的master主分支下载最新的版本到origin/master分支上<br>然后比较本地的master分支和origin/master分支的差别<br>最后进行合并<br>上述过程其实可以用以下更清晰的方式来进行:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git fetch origin master:tmp</span><br><span class="line">git diff tmp </span><br><span class="line">git merge tmp</span><br></pre></td></tr></table></figure>

<p>从远程获取最新的版本到本地的tmp分支上<br>之后再进行比较合并</p>
<h5 id="2-使用git-pull-更新，相当于是从远程获取最新版本并merge到本地"><a href="#2-使用git-pull-更新，相当于是从远程获取最新版本并merge到本地" class="headerlink" title="2.使用git pull 更新，相当于是从远程获取最新版本并merge到本地"></a>2.使用git pull 更新，相当于是从远程获取最新版本并merge到本地</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git pull origin master</span><br></pre></td></tr></table></figure>

<p>上述命令其实相当于git fetch 和 git merge<br>在实际使用中，git fetch更安全一些<br>因为在merge前，我们可以查看更新情况，然后再决定是否合并</p>
<h2 id="III-本地改动导致git-pull出现Error解决方法"><a href="#III-本地改动导致git-pull出现Error解决方法" class="headerlink" title="III. 本地改动导致git pull出现Error解决方法"></a>III. 本地改动导致git pull出现Error解决方法</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">From https://github.com/EvilicLufas/TyporaAssets</span><br><span class="line"> * branch            master     -&gt; FETCH_HEAD</span><br><span class="line">   278ba10..83d7801  master     -&gt; origin/master</span><br><span class="line">error: Your local changes to the following files would be overwritten by merge:</span><br><span class="line">        typoraNote/待办事项（2019-10-10  到   10 -28）.md</span><br><span class="line">Please commit your changes or stash them before you merge.</span><br><span class="line">Aborting</span><br><span class="line">Updating f90196a..83d7801</span><br></pre></td></tr></table></figure>

<p> 通过git stash将工作区恢复到上次提交的内容，同时备份本地所做的修改，之后就可以正常git pull了，git pull完成后，执行git stash pop将之前本地做的修改应用到当前工作区。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git stash</span><br><span class="line">git pull</span><br><span class="line">git stash pop</span><br></pre></td></tr></table></figure>

<p>git stash: 备份当前的工作区的内容，从最近的一次提交中读取相关内容，让工作区保证和上次提交的内容一致。同时，将当前的工作区内容保存到Git栈中。</p>
<p>git pull:拉取服务器上的代码；</p>
<p>git stash pop: 从Git栈中读取最近一次保存的内容，恢复工作区的相关内容。由于可能存在多个Stash的内容，所以用栈来管理，pop会从最近的一个stash中读取内容并恢复。</p>
<p>git stash list: 显示Git栈内的所有备份，可以利用这个列表来决定从那个地方恢复。</p>
<p>git stash clear: 清空Git栈。此时使用gitg等图形化工具会发现，原来stash的哪些节点都消失了。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/11/12/hello-world/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Vellichor">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Vellichor Kyst">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/11/12/hello-world/" itemprop="url">Hello World</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-11-12T01:48:42+08:00">
                2019-11-12
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/10/11/Gossip%E7%AE%97%E6%B3%95%E7%9A%84%E7%A0%94%E7%A9%B6%E4%B8%8E%E5%AE%9E%E7%8E%B0(multi-thread)/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Vellichor">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Vellichor Kyst">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/10/11/Gossip%E7%AE%97%E6%B3%95%E7%9A%84%E7%A0%94%E7%A9%B6%E4%B8%8E%E5%AE%9E%E7%8E%B0(multi-thread)/" itemprop="url">Gossip算法的研究与实现(Multi-thread using Java)</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-10-11T20:27:13+08:00">
                2019-10-11
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Gossip算法的研究与实现-Multi-thread-using-Java"><a href="#Gossip算法的研究与实现-Multi-thread-using-Java" class="headerlink" title="Gossip算法的研究与实现(Multi-thread using Java)"></a>Gossip算法的研究与实现(Multi-thread using Java)</h1><p>[TOC]</p>
<hr>
<h2 id="Chapter-I-Gossip算法介绍"><a href="#Chapter-I-Gossip算法介绍" class="headerlink" title="Chapter I. Gossip算法介绍"></a>Chapter I. Gossip算法介绍</h2><h4 id="1-算法背景"><a href="#1-算法背景" class="headerlink" title="1.算法背景"></a>1.算法背景</h4><p>​        由于卡夫卡集群的特性，在系统运行一段时间后（默认配置是7天），会自动清除掉过期的记录，因此每个周期之后加入的节点都会丢失一部分数据。于是，我们需要一个机制能不依赖卡夫卡集群来实现数据的一致性。</p>
<p>​        这就是 Gossip算法。当卡夫卡集群无法保证数据一致性时，通过此算法，保证系统最终数据一致。同时，还可支持节点间各种类型的消息传播。</p>
<h4 id="2-Gossip算法概述"><a href="#2-Gossip算法概述" class="headerlink" title="2.Gossip算法概述"></a>2.Gossip算法概述</h4><h5 id="2-1-算法简介"><a href="#2-1-算法简介" class="headerlink" title="2.1 算法简介"></a>2.1 算法简介</h5><blockquote>
<p>Gossip, or anti-entropy,  is an attractive way of replicating state that does not have strong consistency requirements</p>
</blockquote>
<p>​        顾名思义，类似于流言传播的概念，Gossip是一种可以按照自己的期望自行选择与之交换信息的节点的通信方式</p>
<p>​        在一个有界网络中，每个节点都随机地与其他节点通信，经过一番杂乱无章的通信，最终所有节点的状态都会达成一致。每个节点可能知道所有其他节点，也可能仅知道几个邻居节点，只要这些节可以通过网络连通，最终他们的状态都是一致的，当然这也是疫情传播的特点。</p>
<p>​        Gossip是一种<strong>去中心化</strong>、<strong>容错</strong>而又<strong>最终一致性</strong>的绝妙算法，其收敛性不但得到证明还具有<strong>指数级</strong>的收敛速度。使用 Gossip 的系统可以很容易的将 Server扩展到更多的节点，满足弹性扩展轻而易举。</p>
<p>​        Gossip常见于大规模、无中心的网络系统，可以用于众多能接受“最终一致性”的领域：失败检测、路由同步、Pub/Sub、动态负载均衡。</p>
<h5 id="2-2-算法特点"><a href="#2-2-算法特点" class="headerlink" title="2.2 算法特点"></a>2.2 算法特点</h5><p>​        Gossip不要求节点知道所有其他节点，因此具有<strong>去中心化</strong>的特点，节点之间完全对等，不需要任何的中心节点。</p>
<p>​        Gossip算法又被称为反熵（Anti-Entropy），熵是物理学上的一个概念，代表杂乱无章，而反熵就是在杂乱无章中寻求一致，这充分说明了Gossip的特点：</p>
<blockquote>
<p>在一个有界网络中，每个节点都随机地与其他节点通信，经过一番杂乱无章的通信，最终所有节点的状态都会达成一致。每个节点可能知道所有其他节点，也可能仅知道几个邻节点，只要这些节可以通过网络连通，最终他们的状态都是一致的。</p>
</blockquote>
<p>​        Gossip算法是一个最终一致性算法，其无法保证在某个时刻所有节点状态一致，但可以保证在”最终“所有节点一致，<strong>”最终“是一个现实中存在，但理论上无法证明的时间点。</strong></p>
<h5 id="2-3-Gossip协议满足的条件"><a href="#2-3-Gossip协议满足的条件" class="headerlink" title="2.3 Gossip协议满足的条件"></a>2.3 Gossip协议满足的条件</h5><ul>
<li>协议的核心包括周期性，成对性，内部进程交互</li>
<li>交互期间的信息量大小固定</li>
<li>节点交互后，至少一个agent获知另一个agent的状态</li>
<li>通信不可靠</li>
<li>交流的频率远远低于消息的传输延迟</li>
<li>对端选择的随机性，或者从全集，或者从部分集合</li>
<li>由于副本的存在，传输的信息具有隐式冗余</li>
</ul>
<h5 id="2-4-协调机制"><a href="#2-4-协调机制" class="headerlink" title="2.4 协调机制"></a>2.4 协调机制</h5><p>​        协调机制是讨论在每次2个节点通信时，如何交换数据能达到最快的一致性，也即消除两个节点的不一致性。<br>​        协调所面临的最大问题是，因为受限于网络负载，不可能每次都把一个节点上的数据发送给另外一个节点，也即每个Gossip的消息大小都有上限。在有限的空间上有效率地交换所有的消息是协调要解决的主要问题。</p>
<blockquote>
<p>“Efficient Reconciliation and Flow Control for Anti-Entropy Protocols”中描述了两种同步机制<br><strong>1）precise reconciliation</strong></p>
<blockquote>
<p>​        precise reconciliation希望在每次通信周期内都非常准确地消除双方的不一致性，具体表现为相互发送对方需要更新的数据，因为每个节点都在并发与多个节点通信，理论上很难做到。precise reconciliation需要给每个数据项独立地维护自己的version，在每次交互是把所有的(key,value,version)发送到目标进行比对，从而找出双方不同之处从而更新。但因为Gossip消息存在大小限制，因此每次选择发送哪些数据就成了问题。当然可以随机选择一部分数据，也可确定性的选择数据。对确定性的选择而言，可以有最老优先（根据版本）和最新优先两种，最老优先会优先更新版本最新的数据，而最新更新正好相反，这样会造成老数据始终得不到机会更新，也即饥饿。</p>
</blockquote>
<p><strong>2）Scuttlebutt Reconciliation</strong></p>
<blockquote>
<p>​        Scuttlebutt Reconciliation 与precise reconciliation不同之处是，Scuttlebutt Reconciliation不是为每个数据都维护单独的版本号，而是为每个节点上的宿主数据维护统一的version。比如节点P会为(p1,p2,…)维护一个一致的全局version，相当于把所有的宿主数据看作一个整体，当与其他节点进行比较时，只需比较这些宿主数据的最高version，如果最高version相同说明这部分数据全部一致，否则再进行precise reconciliation。</p>
</blockquote>
</blockquote>
<h5 id="2-5-Merkle-tree"><a href="#2-5-Merkle-tree" class="headerlink" title="2.5 Merkle tree"></a>2.5 Merkle tree</h5><p>​        信息同步无疑是gossip的核心，Merkle tree(MT)是一个非常适合同步的数据结构。<br>​        简单来说 Merkle tree就是一颗hash树，在这棵树中，叶子节点的值是一些hash值、非叶节点的值均是由其子节点值计算hash得来的，这样，一旦某个文件被修改，修改时间的信息就会迅速传播到根目录。需要同步的系统只需要不断查询跟节点的hash，一旦有变化，顺着树状结构就能够在 logN 级别的时间找到发生变化的内容，马上同步。<br>​        在Dynamo中，每个节点保存一个范围内的key值，不同节点间存在有相互交迭的key值范围。在去熵操作中，考虑的仅仅是某两个节点间共有的key值范围。MT的叶子节点即是这个共有的key值范围内每个key的hash，通过叶子节点的hash自底向上便可以构建出一颗MT。Dynamo首先比对MT根处的hash，如果一致则表示两者完全一致，否则将其子节点交换并继续比较的过程。</p>
<h5 id="2-6-时间复杂度-logN-的证明"><a href="#2-6-时间复杂度-logN-的证明" class="headerlink" title="2.6 时间复杂度 logN 的证明"></a>2.6 时间复杂度 logN 的证明</h5><p><img src="Gossip%E7%AE%97%E6%B3%95%E7%9A%84%E7%A0%94%E7%A9%B6%E4%B8%8E%E5%AE%9E%E7%8E%B0(multi-thread).assets/1570799966173.png" alt="1570799966173"></p>
<p><img src="Gossip%E7%AE%97%E6%B3%95%E7%9A%84%E7%A0%94%E7%A9%B6%E4%B8%8E%E5%AE%9E%E7%8E%B0(multi-thread).assets/1570799985330.png" alt="1570799985330"></p>
<h5 id="2-7-算法具体描述"><a href="#2-7-算法具体描述" class="headerlink" title="2.7 算法具体描述"></a>2.7 算法具体描述</h5><h6 id="2-7-1-gossip-协议的类型"><a href="#2-7-1-gossip-协议的类型" class="headerlink" title="2.7.1 gossip 协议的类型"></a>2.7.1 gossip 协议的类型</h6><p>前面说了节点会将信息传播到整个网络中，那么节点在什么情况下发起信息交换？这就涉及到 gossip 协议的类型。目前主要有两种方法：</p>
<p>Anti-Entropy（反熵）：以固定的概率传播所有的数据<br>Rumor-Mongering（谣言传播）：仅传播新到达的数据</p>
<h6 id="2-7-2-Anti-Entropy"><a href="#2-7-2-Anti-Entropy" class="headerlink" title="2.7.2 Anti-Entropy"></a>2.7.2 Anti-Entropy</h6><p>Anti-Entropy 的主要工作方式是：每个节点周期性地随机选择其他节点，然后通过互相交换自己的所有数据来消除两者之间的差异。Anti-Entropy 这种方法非常可靠，但是每次节点两两交换自己的所有数据会带来非常大的通信负担，以此不会频繁使用。</p>
<p>Anti-Entropy 使用“simple epidemics”的方式，所以其包含两种状态：susceptible 和 infective，这种模型也称为 SI model。处于 infective 状态的节点代表其有数据更新，并且会将这个数据分享给其他节点；处于 susceptible 状态的节点代表其并没有收到来自其他节点的更新。</p>
<h6 id="2-7-3-Rumor-Mongering"><a href="#2-7-3-Rumor-Mongering" class="headerlink" title="2.7.3 Rumor-Mongering"></a>2.7.3 Rumor-Mongering</h6><p>Rumor-Mongering 的主要工作方式是：当一个节点有了新的信息后，这个节点变成活跃状态，并周期性地联系其他节点向其发送新信息。直到所有的节点都知道该新信息。因为节点之间只是交换新信息，所有大大减少了通信的负担。</p>
<p>Rumor-Mongering 使用“complex epidemics”方法，相比 Anti-Entropy 多了一种状态：removed，这种模型也称为 SIR model。处于 removed 状态的节点说明其已经接收到来自其他节点的更新，但是其并不会将这个更新分享给其他节点。</p>
<p>因为 Rumor 消息会在某个时间标记为 removed，然后不会发送给其他节点，所以 Rumor-Mongering 类型的 gossip 协议有极小概率使得更新不会达到所有节点。</p>
<p>一般来说，为了在通信代价和可靠性之间取得折中，需要将这两种方法结合使用。</p>
<h6 id="2-7-4-gossip-协议的通讯方式"><a href="#2-7-4-gossip-协议的通讯方式" class="headerlink" title="2.7.4 gossip 协议的通讯方式"></a>2.7.4 gossip 协议的通讯方式</h6><p>不管是 Anti-Entropy 还是 Rumor-Mongering 都涉及到节点间的数据交互方式，节点间的交互方式主要有三种：Push、Pull 以及 Push&amp;Pull。</p>
<p>Push：发起信息交换的节点 A 随机选择联系节点 B，并向其发送自己的信息，节点 B 在收到信息后更新比自己新的数据，一般拥有新信息的节点才会作为发起节点。<br>Pull：发起信息交换的节点 A 随机选择联系节点 B，并从对方获取信息。一般无新信息的节点才会作为发起节点。<br>Push&amp;Pull：发起信息交换的节点 A 向选择的节点 B 发送信息，同时从对方获取数据，用于更新自己的本地数据。</p>
<h2 id="Chapter-II-作业描述与实现"><a href="#Chapter-II-作业描述与实现" class="headerlink" title="Chapter II. 作业描述与实现"></a>Chapter II. 作业描述与实现</h2><h4 id="1-作业描述"><a href="#1-作业描述" class="headerlink" title="1.作业描述"></a>1.作业描述</h4><h5 id="1-1-简述"><a href="#1-1-简述" class="headerlink" title="1.1 简述"></a>1.1 简述</h5><p>使用Gossiping协议实现去中心化的平均数算法（使用任意语言均可）</p>
<blockquote>
<p>假设初始所有GossipNode线程的Message为0，为Passive即不包含任何消息的节点，而在第一轮迭代开始时一个GossipNode的Messge为10，为Active，则该Node将会随机选择其他节点进行信息传播即感染，而进行选择的Node与被选择的Node会消除两者之间的信息差异，即进行Message取平均数，被感染的Node与初始Message为10的Node的Message都变为5，此后获得了信息的Node即为Active可以在每轮循环中随机选择其他（<strong>包括已经被隔离的</strong>)节点进行感染，直到他兴趣值不断降低被确认为DeadNode被Kill也就是隔离为止 ，<strong>隔离</strong>仅仅意味着该节点无法主动选取其他节点进行信息传播</p>
</blockquote>
<h5 id="1-2-定义"><a href="#1-2-定义" class="headerlink" title="1.2 定义"></a>1.2 定义</h5><table>
<thead>
<tr>
<th align="left">Definition</th>
<th>Meaning</th>
</tr>
</thead>
<tbody><tr>
<td align="left">误差</td>
<td>整个算法的核心在于携带初始信息的节点在Gossip之后使得其他节点通过传播均取得相同的信息，假设 InitialActiveNode.getMessage() = 10, 而numberOfNodes = 10,则初始信息的平均值与理想状况下Gossip结束后的Message平均值应该都为1。在实际算法运行中，可能最后节点携带的信息值为1.05或0.98一类的，此时用 理想的平均值 1 减去 其信息值 , 求差值之后将所有节点的差值求平均值，即为所求算法误差的平均值</td>
</tr>
<tr>
<td align="left">收敛轮数</td>
<td>整个Gossip从开始到终止迭代的轮数</td>
</tr>
<tr>
<td align="left">K 值</td>
<td>K是用来计算兴趣值的影响因子</td>
</tr>
<tr>
<td align="left">节点隔离</td>
<td><strong>隔离</strong>仅仅意味着该节点无法主动选取其他节点进行信息传播，被隔离的节点仍然可以被其他ActiveNode选择为信息传播的目标。具体实现方法为 在每轮gossip开始之前，所有独立的ActiveNode生成一个随机数verdictNum(裁决数字)，取值范围在（0,1）之内,对每个Active的节点进行判定，若该节点的valueOfInterest &lt; verdictNum，则该节点被隔离 (一次生成一个verdictNum对所有节点进行相同条件的判定，sounds fair, 但是并不适用于分布式系统)</td>
</tr>
<tr>
<td align="left">兴趣值</td>
<td>获得了信息的Node即为Active可以在每轮循环中随机选择其他节点进行感染，在每轮GossipNode开始感染之前，其成功传播的概率为valueOfInterest，每轮开始传播之前进行一次判定，也可以认为valueOfInterest为该节点存活的概率，若判定无法传播也即没有兴趣，会被确立为死节点并被清除, valueOfInterest *= 1/k  ,k为常值,他选择的有可能为Message为0的PassiveNode也有可能为Message不为0的其他ActiveNode,而当一个Message = c 的 ActiveNode与另一个同样Message = c的Node进行交换时，由于信息相同而受挫，每次受挫都会导致该Node的兴趣值降低，即为</td>
</tr>
</tbody></table>
<p>$$<br>valueOfInterest = 1/(k)^n   【n为受挫的次数】<br>$$</p>
<p>可以理解为 valueOfInterest 为每轮Gossip开始时决定该节点是否继续存活保持Active而不被隔离的几率</p>
<h5 id="1-3-结果要求"><a href="#1-3-结果要求" class="headerlink" title="1.3 结果要求"></a>1.3 结果要求</h5><table>
<thead>
<tr>
<th>Requirements ( 难度 =  Level 5 )</th>
</tr>
</thead>
<tbody><tr>
<td>1.误差与K值之间的关系图</td>
</tr>
<tr>
<td>2.误差与节点个数之间的关系图</td>
</tr>
<tr>
<td>3.收敛轮数与K值之间的关系图</td>
</tr>
<tr>
<td>4.收敛轮数与节点个数之间的关系图</td>
</tr>
<tr>
<td>5.多线程模拟多节点代码</td>
</tr>
<tr>
<td>6.输入输出结果展示</td>
</tr>
</tbody></table>
<h4 id="2-代码实现"><a href="#2-代码实现" class="headerlink" title="2.代码实现"></a>2.代码实现</h4><h5 id="1-GossipNode"><a href="#1-GossipNode" class="headerlink" title="1.GossipNode"></a>1.GossipNode</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">package</span> com.company;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Objects;</span><br><span class="line"><span class="keyword">import</span> java.util.Random;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * A class representing a gossip Node.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> Vellichor</span></span><br><span class="line"><span class="comment"> * ID: 20175045</span></span><br><span class="line"><span class="comment"> * Name: 高歌</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GossipNode</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * message ---- 信息</span></span><br><span class="line"><span class="comment">     * downTimes ---------------受挫次数</span></span><br><span class="line"><span class="comment">     * valueOfInterest ------- 兴趣值</span></span><br><span class="line"><span class="comment">     * rounds-----------轮数</span></span><br><span class="line"><span class="comment">     * status ---------- 1 - Active      0- Passive      2- Dead</span></span><br><span class="line"><span class="comment">     * id ---------- 节点 ID 在生成 ArrayList时特定设立为与 Thread 线程与 节点索引相同的数字便于识别</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">volatile</span> Double message;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">int</span> downTimes;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">volatile</span> Double valueOfInterest;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> rounds;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">int</span> status;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> id;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    GossipNode(Double message, <span class="keyword">int</span> downTimes, Double valueOfInterest, <span class="keyword">int</span> rounds, <span class="keyword">int</span> status, <span class="keyword">int</span> id) &#123;</span><br><span class="line">        <span class="keyword">this</span>.message = message;</span><br><span class="line">        <span class="keyword">this</span>.downTimes = downTimes;</span><br><span class="line">        <span class="keyword">this</span>.valueOfInterest = valueOfInterest;</span><br><span class="line">        <span class="keyword">this</span>.rounds = rounds;</span><br><span class="line">        <span class="keyword">this</span>.status = status;</span><br><span class="line">        <span class="keyword">this</span>.id = id;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * return a random number which is not equal to another unwanted number</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> unwantedNum</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> numberRange</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">getRandomNum</span><span class="params">(<span class="keyword">int</span> unwantedNum, <span class="keyword">int</span> numberRange)</span> </span>&#123;</span><br><span class="line">        Random random = <span class="keyword">new</span> Random();</span><br><span class="line">        <span class="keyword">int</span> randomNum = random.nextInt(numberRange) + <span class="number">1</span>;<span class="comment">//用于生成该节点在ArrayList中的索引</span></span><br><span class="line">        <span class="keyword">if</span> (randomNum == unwantedNum) &#123;</span><br><span class="line">            getRandomNum(unwantedNum, numberRange);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> randomNum;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 随机生成并返回一个[0.1)的 Double数值 用于判断节点是否被隔离</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> Double <span class="title">generatorDouble0To1</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> Random().nextDouble();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 用于求 两个节点交换信息后的平均信息值</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> Message_1</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> Message_2</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> Double <span class="title">getAvgMessage</span><span class="params">(Double Message_1, Double Message_2)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> (Message_1 + Message_2) / <span class="number">2</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> targetNode      当前节点所选择感染的目标节点</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> value_K         K值  用于影响兴趣值的递减</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> minusToleration 对于判断节点携带信息是否相同时所用的误差限度（因为 Double 为高精度数字）</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> 1--节点继续保持活跃  2----节点被隔离</span></span><br><span class="line"><span class="comment">     * （默认 status = 0 时节点为未携带信息时的 Passive 状态）</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">startGossiping</span><span class="params">(GossipNode targetNode, <span class="keyword">int</span> value_K, Double minusToleration)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//每轮遍历ArrayList找寻存活的Active节点进行一轮的感染</span></span><br><span class="line">        System.out.println();</span><br><span class="line">        System.out.println(<span class="string">"当前节点  Message = "</span> + message + <span class="string">" down"</span> +</span><br><span class="line">                <span class="string">"Times =  "</span> + downTimes + <span class="string">"兴趣值valueOfInterest = "</span> + valueOfInterest + <span class="string">"状态Status = "</span> + status);</span><br><span class="line">        System.out.println(<span class="string">"生成（0，1）内的随机数 对该节点进行判定"</span>);</span><br><span class="line">        Double verdictNum = generatorDouble0To1();</span><br><span class="line">        System.out.println(<span class="string">"生成随机数为 "</span> + verdictNum);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (valueOfInterest &gt;= verdictNum) &#123;</span><br><span class="line">            System.out.println(<span class="string">"兴趣值上界 &gt;= 判定数字  在兴趣值区间内，节点继续保持活跃"</span>);</span><br><span class="line">            <span class="comment">//若节点为活跃状态，开始寻找被感染者</span></span><br><span class="line">            <span class="comment">//轮数加1</span></span><br><span class="line">            rounds++;</span><br><span class="line">            System.out.println(<span class="string">"&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; 轮数:  "</span> + rounds + <span class="string">" &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;"</span>);</span><br><span class="line">            System.out.println(<span class="string">"------------------节点 "</span> + id + <span class="string">" 号开始寻找被感染者---------------- "</span>);</span><br><span class="line"></span><br><span class="line">            <span class="comment">//若二者信息相同(由于为高精度Double，故考虑二者绝对值差值在0.05之内就为相同， ActiveNode节点受挫， 受挫次数 downTimes+1</span></span><br><span class="line">            <span class="keyword">double</span> minusValue = targetNode.message - message;</span><br><span class="line">            <span class="keyword">if</span> (Math.abs(minusValue) &lt; minusToleration) &#123;</span><br><span class="line">                downTimes++;</span><br><span class="line">                <span class="comment">//根据改变的受挫次数设置 新的兴趣值</span></span><br><span class="line">                valueOfInterest = message / value_K;</span><br><span class="line"></span><br><span class="line">                System.out.println(<span class="string">"二者携带信息相同（信息差值在允许范围内）： currentNodeMessage: "</span> + message + <span class="string">" targetNodeMessage = "</span> + targetNode.message );</span><br><span class="line">                System.out.println(<span class="string">"感染者受挫，"</span> + <span class="string">"downTimes = "</span> + downTimes + <span class="string">"兴趣值valueOfInterest = "</span> + valueOfInterest);</span><br><span class="line">            &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">                <span class="comment">//二者信息 均被设置为 其信息的平均值</span></span><br><span class="line">                Double avgMessage = getAvgMessage(targetNode.message, message);</span><br><span class="line">                targetNode.setMessage(avgMessage);</span><br><span class="line">                message = avgMessage;</span><br><span class="line">                System.out.println(<span class="string">"交换信息后 二者信息均变为 avgMessage = "</span> + avgMessage);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">switch</span>(targetNode.status) &#123;</span><br><span class="line">                <span class="keyword">case</span> <span class="number">0</span>:</span><br><span class="line">                    targetNode.setStatus(<span class="number">1</span>);<span class="comment">//该节点状态被设置为活跃</span></span><br><span class="line">                    System.out.println(<span class="string">"节点被感染 Status设置为 1 = Active"</span>);</span><br><span class="line">                    targetNode.setRounds(rounds);<span class="comment">//被感染节点初次被感染，继承当前节点的轮数</span></span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                <span class="keyword">case</span> <span class="number">1</span>:</span><br><span class="line">                    System.out.println(<span class="string">"节点之前已经被感染 Status为 1 = Active 保持不变"</span>);</span><br><span class="line">                <span class="keyword">case</span> <span class="number">2</span>:</span><br><span class="line">                    System.out.println(<span class="string">"被感染者已经被隔离, status 不变 仍然为 2 = Dead "</span>);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span>;<span class="comment">//节点继续保持活跃</span></span><br><span class="line"></span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            System.out.println(<span class="string">"兴趣值上界 &lt; 判定数字    判定数字不在兴趣值区间内，节点被隔离, 轮数不会增加"</span>);</span><br><span class="line">            targetNode.setStatus(<span class="number">2</span>);</span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> <span class="number">2</span>;<span class="comment">//节点被隔离</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">	<span class="comment">// 部分代码省略</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h5 id="2-initGossip"><a href="#2-initGossip" class="headerlink" title="2.initGossip"></a>2.initGossip</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.company;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.Semaphore;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">initGossip</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> num;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">initGossip</span><span class="params">(<span class="keyword">int</span> num)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.num = num;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 初始化节点列表</span></span><br><span class="line"><span class="comment">     * message ---- 信息  Default----0.0</span></span><br><span class="line"><span class="comment">     * downTimes ---------------受挫次数----Default------0</span></span><br><span class="line"><span class="comment">     * valueOfInterest ------- 兴趣值--Default----1.0</span></span><br><span class="line"><span class="comment">     * rounds-----------轮数--Default------0</span></span><br><span class="line"><span class="comment">     * status ---------- 1 - Active      0- Passive      2- Dead----Default------0</span></span><br><span class="line"><span class="comment">     * id ---------- 节点 ID 在生成 ArrayList时特定设立为与 Thread 线程与 节点索引相同的数字便于识别</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">static</span> ArrayList&lt;GossipNode&gt; <span class="title">initGossipNodeList</span><span class="params">(<span class="keyword">int</span> num)</span></span>&#123;</span><br><span class="line">        ArrayList&lt;GossipNode&gt; nodeArrayList = <span class="keyword">new</span> ArrayList&lt;&gt;(num);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; num; i++) &#123;</span><br><span class="line">            <span class="comment">// 首先将所有节点设置为 Default 条件</span></span><br><span class="line">            GossipNode defaultNode = <span class="keyword">new</span> GossipNode(<span class="number">0.0</span>, <span class="number">0</span>, <span class="number">1.0</span>, <span class="number">0</span>, <span class="number">0</span>, i);</span><br><span class="line">            nodeArrayList.add(defaultNode);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 将第一个节点设置为 Status=1--Active &amp; Message=1.0</span></span><br><span class="line">        nodeArrayList.get(<span class="number">0</span>).setStatus(<span class="number">1</span>);</span><br><span class="line">        nodeArrayList.get(<span class="number">0</span>).setMessage(<span class="number">1.0</span>);</span><br><span class="line">        System.out.println(<span class="string">"节点初始化全部完成，索引与ID皆为0的 节点被设置为 Message = 1.0 的初始感染节点"</span>);</span><br><span class="line">        <span class="keyword">return</span> nodeArrayList;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 初始化信号量都为1个</span></span><br><span class="line">    <span class="function"><span class="keyword">static</span> ArrayList&lt;Semaphore&gt; <span class="title">initSemaphoreList</span><span class="params">(<span class="keyword">int</span> num)</span> </span>&#123;</span><br><span class="line">        ArrayList&lt;Semaphore&gt; semaphoreArrayList = <span class="keyword">new</span> ArrayList&lt;&gt;(num);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; num; i++) &#123;</span><br><span class="line">            semaphoreArrayList.add(<span class="keyword">new</span> Semaphore(<span class="number">1</span>));</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(<span class="string">"信号量初始化完成"</span>);</span><br><span class="line">        <span class="keyword">return</span> semaphoreArrayList;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h5 id="3-GossipingMultiThread"><a href="#3-GossipingMultiThread" class="headerlink" title="3.GossipingMultiThread"></a>3.GossipingMultiThread</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.company;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"><span class="keyword">import</span> java.text.DecimalFormat;</span><br><span class="line"><span class="keyword">import</span> java.text.SimpleDateFormat;</span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.Date;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.ExecutorService;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.Executors;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.Semaphore;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">GossipingMultiThread</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * value_K : K值 决定兴趣值递减程度</span></span><br><span class="line"><span class="comment">     * numOfNodes : 节点数  同时也为线程数</span></span><br><span class="line"><span class="comment">     * minusToleration : 判断 Message 是否相同时的误差容忍度</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> GossipSettings  settings = <span class="keyword">new</span> GossipSettings(<span class="number">3</span>,<span class="number">20</span>,<span class="number">0.01</span>);</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> numOfNodes = settings.getNumberOfnodes();</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> value_K = settings.getValue_K();</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Double minusToleration = settings.getMinusToleration();<span class="comment">//判断Message是否相同时候的误差容忍度</span></span><br><span class="line">    <span class="comment">//调用 initGossip中的方法，在建立ArrayList时已经完成了 ArrayList中数据的初始化</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> ArrayList&lt;GossipNode&gt; nodeArrayList = initGossip.initGossipNodeList(numOfNodes);</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> ArrayList&lt;Semaphore&gt; semaphoreArrayList = initGossip.initSemaphoreList(numOfNodes);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//使用ArrayList控制线程池中线程的关闭</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> ArrayList&lt;Integer&gt; threadPoolStartList = <span class="keyword">new</span> ArrayList&lt;Integer&gt;(numOfNodes);</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> ArrayList&lt;Integer&gt; threadPoolEndList = <span class="keyword">new</span> ArrayList&lt;Integer&gt;(numOfNodes);</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//将控制台Console中的输出全部打印到 consoleOutput.txt 中</span></span><br><span class="line">        PrintStream oldPrintStream = System.out;</span><br><span class="line">        FileOutputStream bos = <span class="keyword">new</span> FileOutputStream(<span class="string">"consoleOutput.txt"</span>);</span><br><span class="line">        MultiOutputStream multi = <span class="keyword">new</span> MultiOutputStream(<span class="keyword">new</span> PrintStream(bos),oldPrintStream);</span><br><span class="line">        System.setOut(<span class="keyword">new</span> PrintStream(multi));</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;numOfNodes;i++)&#123;</span><br><span class="line">            threadPoolStartList.add(<span class="number">0</span>);</span><br><span class="line">            threadPoolEndList.add(<span class="number">0</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//用于判断线程池的</span></span><br><span class="line">        <span class="comment">// 开线程池，每个线程搭载一个节点</span></span><br><span class="line">        ExecutorService ex = Executors.newCachedThreadPool();</span><br><span class="line">        ex.execute(<span class="keyword">new</span> ActiveMessageThread(<span class="number">0</span>));</span><br><span class="line">        <span class="comment">// 关闭线程池的条件</span></span><br><span class="line">        <span class="keyword">int</span> allEqual = <span class="number">0</span>;</span><br><span class="line"><span class="comment">//        while (shutDownSign == 0 )&#123;</span></span><br><span class="line">        <span class="keyword">while</span> (allEqual == <span class="number">0</span> &amp;&amp; !threadPoolEndList.isEmpty() )&#123;</span><br><span class="line">            allEqual = <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;numOfNodes;i++)&#123;</span><br><span class="line">                <span class="keyword">if</span> (threadPoolStartList.get(i).equals(threadPoolEndList.get(i)))&#123;</span><br><span class="line">                    allEqual = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">                &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">                    allEqual = <span class="number">0</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//如果记录线程开关的两个 ArrayList 对应索引位置的数值都相同 前 第一个启动的线程已经结束</span></span><br><span class="line">            <span class="comment">//终止线程池</span></span><br><span class="line"><span class="comment">//            if (threadPoolEndList.get(0) == 1 &amp;&amp; allEqual ==1)&#123;</span></span><br><span class="line"><span class="comment">//                shutDownSign = 1;</span></span><br><span class="line"><span class="comment">//                System.out.println("如果记录线程开关的两个 ArrayList 对应索引位置的数值都相同 而且 第一个启动的线程已经结束 ");</span></span><br><span class="line"><span class="comment">//                System.out.println("终止线程池");</span></span><br><span class="line"><span class="comment">//            &#125;</span></span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line">        ex.shutdown();</span><br><span class="line">        <span class="comment">// 确认线程池运行完毕</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//        //控制台输出可能受线程池关闭时间影响不准,准确输出以该文件为准</span></span><br><span class="line"><span class="comment">//        writeResult();</span></span><br><span class="line">        <span class="comment">// 写日志</span></span><br><span class="line">        CsvWriter.writeResultToCSV(nodeArrayList,value_K);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>;i&lt;numOfNodes;i++)&#123;</span><br><span class="line">            System.out.println(nodeArrayList.get(i).getRounds());</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 线程类</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">ActiveMessageThread</span> <span class="keyword">implements</span> <span class="title">Runnable</span> </span>&#123;</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">int</span> currentIndex;<span class="comment">// 该线程搭载的信息发送节点编号</span></span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">private</span> <span class="title">ActiveMessageThread</span><span class="params">(<span class="keyword">int</span> currentIndex)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.currentIndex = currentIndex;<span class="comment">// 初始化时为线程指定所搭载的节点编号</span></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">                <span class="comment">//序号为currentIndex的线程开始运行</span></span><br><span class="line">                <span class="comment">//threadPoolStartList中索引为currentIndex的数值设为1</span></span><br><span class="line">                threadPoolStartList.set(currentIndex,<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">                <span class="keyword">int</span> gossipResult = <span class="number">1</span>;<span class="comment">// 初始化是否传递成功</span></span><br><span class="line">                <span class="keyword">int</span> minResource = <span class="number">0</span>;<span class="comment">// 初始化较小编号资源的编号</span></span><br><span class="line">                <span class="keyword">int</span> maxResource = <span class="number">0</span>;<span class="comment">// 初始化较大编号资源的编号</span></span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    <span class="comment">// 随机选择要传达的节点,不能是自己</span></span><br><span class="line">                    <span class="keyword">int</span> targetIndex;</span><br><span class="line">                    <span class="keyword">do</span> &#123;</span><br><span class="line">                        targetIndex = (<span class="keyword">int</span>) (Math.random() * numOfNodes);</span><br><span class="line">                    &#125; <span class="keyword">while</span> (targetIndex == currentIndex);</span><br><span class="line">                    <span class="comment">// 进行资源排序，防止死锁</span></span><br><span class="line">                    <span class="keyword">if</span> (currentIndex &gt; targetIndex) &#123;</span><br><span class="line">                        maxResource = currentIndex;</span><br><span class="line">                        minResource = targetIndex;</span><br><span class="line">                    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                        maxResource = targetIndex;</span><br><span class="line">                        minResource = currentIndex;</span><br><span class="line">                    &#125;</span><br><span class="line">                    <span class="comment">// 先获取小编号信号量</span></span><br><span class="line">                    semaphoreArrayList.get(minResource).acquire();</span><br><span class="line">                    <span class="comment">// 才能获取大编号信号量</span></span><br><span class="line">                    semaphoreArrayList.get(maxResource).acquire();</span><br><span class="line">                    <span class="keyword">int</span> targetStatus = nodeArrayList.get(targetIndex).getStatus();</span><br><span class="line"></span><br><span class="line">                    <span class="comment">// 通过startGossiping发送消息并且获取 当前节点状态</span></span><br><span class="line">                    <span class="comment">//1---------节点继续保持活跃</span></span><br><span class="line">                    <span class="comment">//2----------节点被隔离</span></span><br><span class="line">                    <span class="comment">// gossipResult 表示这轮感染成功开始  targetStatus == 0 表示目标节点尚未被感染 可以开启新线程</span></span><br><span class="line">                    gossipResult = nodeArrayList.get(currentIndex).startGossiping(nodeArrayList.get(targetIndex), value_K, minusToleration);</span><br><span class="line">                    <span class="keyword">if</span> (gossipResult == <span class="number">1</span> &amp;&amp; targetStatus == <span class="number">0</span>) &#123;</span><br><span class="line">                        <span class="comment">// 如果感染了新的节点,就启动搭载他的线程,</span></span><br><span class="line">                        <span class="comment">// 这里如果感染者和易感者的数本来就相等,线程也会启动,因为相当于感染者把感染全部节点的需求传达给了易感者</span></span><br><span class="line">                        <span class="keyword">new</span> Thread(<span class="keyword">new</span> ActiveMessageThread(targetIndex)).start();</span><br><span class="line"></span><br><span class="line">                    &#125;</span><br><span class="line">                &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                    e.printStackTrace();</span><br><span class="line">                &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">                    <span class="comment">// 集体释放信号量</span></span><br><span class="line">                    semaphoreArrayList.get(minResource).release();</span><br><span class="line">                    semaphoreArrayList.get(maxResource).release();</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">// gossipResult = 2 代表节点已经被隔离</span></span><br><span class="line">                <span class="keyword">if</span> (gossipResult == <span class="number">2</span>) &#123;<span class="comment">// 终止线程</span></span><br><span class="line"></span><br><span class="line">                    <span class="comment">//序号为currentIndex的线程开始运行</span></span><br><span class="line">                    <span class="comment">//threadPoolEndList中索引为currentIndex的数值设为1</span></span><br><span class="line"></span><br><span class="line">                    threadPoolEndList.set(currentIndex,<span class="number">1</span>);</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="3-输入输出结果展示"><a href="#3-输入输出结果展示" class="headerlink" title="3.输入输出结果展示"></a>3.输入输出结果展示</h4><h6 id="3-1-Console控制台输出展示"><a href="#3-1-Console控制台输出展示" class="headerlink" title="3.1 Console控制台输出展示"></a>3.1 Console控制台输出展示</h6><p><img src="Gossip%E7%AE%97%E6%B3%95%E7%9A%84%E7%A0%94%E7%A9%B6%E4%B8%8E%E5%AE%9E%E7%8E%B0(multi-thread).assets/1571926475885.png" alt="1571926475885"></p>
<h6 id="3-2-结果数据打印"><a href="#3-2-结果数据打印" class="headerlink" title="3.2 结果数据打印"></a>3.2 结果数据打印</h6><p><img src="Gossip%E7%AE%97%E6%B3%95%E7%9A%84%E7%A0%94%E7%A9%B6%E4%B8%8E%E5%AE%9E%E7%8E%B0(multi-thread).assets/1571926503527.png" alt="1571926503527"></p>
<h4 id="4-结果分析"><a href="#4-结果分析" class="headerlink" title="4.结果分析"></a>4.结果分析</h4><p><img src="Gossip%E7%AE%97%E6%B3%95%E7%9A%84%E7%A0%94%E7%A9%B6%E4%B8%8E%E5%AE%9E%E7%8E%B0(multi-thread).assets/1571924466380.png" alt="1571924466380"></p>
<p><img src="Gossip%E7%AE%97%E6%B3%95%E7%9A%84%E7%A0%94%E7%A9%B6%E4%B8%8E%E5%AE%9E%E7%8E%B0(multi-thread).assets/1571924632284.png" alt="1571924632284"></p>
<p><img src="Gossip%E7%AE%97%E6%B3%95%E7%9A%84%E7%A0%94%E7%A9%B6%E4%B8%8E%E5%AE%9E%E7%8E%B0(multi-thread).assets/1571924730193.png" alt="1571924730193"></p>
<p><img src="Gossip%E7%AE%97%E6%B3%95%E7%9A%84%E7%A0%94%E7%A9%B6%E4%B8%8E%E5%AE%9E%E7%8E%B0(multi-thread).assets/1571924850345.png" alt="1571924850345"></p>
<p><img src="Gossip%E7%AE%97%E6%B3%95%E7%9A%84%E7%A0%94%E7%A9%B6%E4%B8%8E%E5%AE%9E%E7%8E%B0(multi-thread).assets/1571925811832.png" alt="1571925811832"></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  


          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Vellichor</p>
              <p class="site-description motion-element" itemprop="description">Mainly record the thoughts & techniques in shool learning & rearch in AI</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/%20%7C%7C%20archive">
              
                  <span class="site-state-item-count">5</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            

            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Vellichor</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="https://cdn.bootcss.com/jquery/2.1.3/jquery.min.js"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
